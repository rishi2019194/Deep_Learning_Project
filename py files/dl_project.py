# -*- coding: utf-8 -*-
"""DL_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s00cv9cOj3ccU09s4_Zw9vBXF_7uNO0X

# **Importing libraries**
"""

import os
import tensorflow as tf
import numpy as np
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.resnet50 import ResNet50
import matplotlib.pyplot as plt
import torch
from scipy.special import erfinv
import multiprocessing
import tarfile
from google.colab import drive
drive.mount('/content/drive')

"""# **Loading Dataset**"""

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()
# Normalize the input image so that each pixel value is between 0 to 1.
x_train = x_train.astype(np.float32) / 255.0
x_test = x_test.astype(np.float32) / 255.0

IMG_SIZE = 224
num_classes = 100

y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)
y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)

"""# **Building model**"""

def build_model(x_train):
    input_layer = tf.keras.layers.Input(shape=(32,32, 3))
    up_sample_layer = tf.keras.layers.UpSampling2D(size=(7,7))(input_layer)
    model = ResNet50(include_top=False, input_tensor=up_sample_layer, weights="imagenet")
    for layer in model.layers:
        if isinstance(layer, tf.keras.layers.BatchNormalization):
            layer.trainable = True
        else:
            layer.trainable = False

    # # Freeze the layers
    # model.trainable = False
    # Rebuild top
    x = tf.keras.layers.GlobalAveragePooling2D(name="avg_pool")(model.output)
    x = tf.keras.layers.BatchNormalization()(x)

    top_dropout_rate = 0.2
    x = tf.keras.layers.Dropout(top_dropout_rate, name="top_dropout")(x, training = True)
    x = tf.keras.layers.Dense(300, activation = 'relu')(x)
    x = tf.keras.layers.Dropout(0.4)(x, training = True)

    outputs = tf.keras.layers.Dense(num_classes, activation = "sigmoid", name="pred")(x)
    model = tf.keras.Model(input_layer, outputs)
    model.compile(optimizer='adam',
                loss = tf.keras.losses.BinaryCrossentropy(from_logits=False),
                metrics=['accuracy'])

    return model

model = build_model(x_train)

"""# **Training the model**"""

model.fit(x_train,y_train, epochs=10)

"""# **Save trained model**"""

model.save('drive/MyDrive/DL_Project/CFAR100/cfar100_model.keras')

"""# **Loading Saved Model**"""

saved_model = tf.keras.models.load_model('drive/MyDrive/DL_Project/CFAR100/cfar100_model.keras')

"""# **Evaluate on saved model**"""

saved_model.evaluate(x_test[:100],y_test[:100])

"""# **TF-LITE Models - normal and quantized**"""

converter = tf.lite.TFLiteConverter.from_keras_model(saved_model)

tflite_model = converter.convert()

def representative_data_gen():
  for input_value in tf.data.Dataset.from_tensor_slices(x_train).batch(1).take(100):
    yield [input_value]

converter = tf.lite.TFLiteConverter.from_keras_model(saved_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
# Ensure that if any ops can't be quantized, the converter throws an error
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
# Set the input and output tensors to uint8 (APIs added in r2.3)
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

tflite_model_quant = converter.convert()

"""# **Storing the TF-LITE models - with and without quantization**"""

import pathlib

tflite_models_dir = pathlib.Path("/tmp/mnist_tflite_models/")
tflite_models_dir.mkdir(exist_ok=True, parents=True)

# Save the unquantized/float model:
tflite_model_file = tflite_models_dir/"mnist_model.tflite"
tflite_model_file.write_bytes(tflite_model)
# Save the quantized model:
tflite_model_quant_file = tflite_models_dir/"mnist_model_quant.tflite"
tflite_model_quant_file.write_bytes(tflite_model_quant)

tflite_models_dir = 'drive/MyDrive/DL_Project/CFAR100/'

# Save the unquantized/float model:
tflite_model_file = tflite_models_dir + "cfar100_model.tflite"
with open(tflite_model_file, 'wb') as f:
    f.write(tflite_model)
# Save the quantized/:
tflite_quantized_model_file = tflite_models_dir + "cfar100_model_quantized_int8.tflite"
with open(tflite_quantized_model_file, 'wb') as f:
    f.write(tflite_model_quant)

#load model
tflite_models_dir = 'drive/MyDrive/DL_Project/CFAR100/'
model_file_name = 'cfar100_model_quantized_int8.tflite'

interpreter = tf.lite.Interpreter(model_path=tflite_models_dir+model_file_name)

"""# **Find sigmoid quantization parameters**"""

interpreter.allocate_tensors()

# Get information about the input and output tensors
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Assuming the sigmoid layer is the first and only output layer
sigmoid_layer_index = 0

# Get quantization parameters for the sigmoid layer
print(output_details)
output_scale = output_details[sigmoid_layer_index]['quantization_parameters']['scales'][0]
output_zero_point = output_details[sigmoid_layer_index]['quantization_parameters']['zero_points'][0]

print(f"Output scale: {output_scale}")
print(f"Output zero point: {output_zero_point}")

# Helper function to run inference on a TFLite model
def run_tflite_model(tflite_file, test_image_indices):

  # Initialize the interpreter
  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))
  interpreter.allocate_tensors()

  input_details = interpreter.get_input_details()[0]
  output_details = interpreter.get_output_details()[0]

  predictions = np.zeros((len(test_image_indices), 100))
  for i, test_image_index in enumerate(test_image_indices):
    test_image = x_test[test_image_index]
    test_label = y_test[test_image_index]

    # Check if the input type is quantized, then rescale input data to uint8
    if input_details['dtype'] == np.uint8:
      input_scale, input_zero_point = input_details["quantization"]
      test_image = test_image / input_scale + input_zero_point

    test_image = np.expand_dims(test_image, axis=0).astype(input_details["dtype"])
    interpreter.set_tensor(input_details["index"], test_image)
    interpreter.invoke()
    output = interpreter.get_tensor(output_details["index"])[0]
    max_index = np.argmax(output)
    # print(max_index)
    predictions[i][max_index] = 1

  return predictions

# Helper function to evaluate a TFLite model on all images
def evaluate_model(tflite_file, model_type):
  print(len(x_test))
  x_tes = x_test[0:100]
  y_tes = y_test[0:100]
  # print(x_tes)
  test_image_indices = range(x_tes.shape[0])
  print(len(test_image_indices))
  predictions = run_tflite_model(tflite_file, test_image_indices)
  print(predictions)
  accuracy = accuracy_score(predictions, y_tes)*100
  f1_score_val = f1_score(predictions, y_tes, average='micro')

  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (
      model_type, accuracy, len(x_tes )))
  print('%s model f1 score is %.4f%% (Number of test samples=%d)' % (
      model_type, f1_score_val, len(x_tes )))

evaluate_model(tflite_model_file, model_type="Float")

evaluate_model(tflite_model_quant_file, model_type="Quantized")

def run_tflite_model_single_sample_raw(interpreter, input_details, output_details, test_image):
    # Check if the input type is quantized, then rescale input data to uint8
    if input_details['dtype'] == np.uint8:
      input_scale, input_zero_point = input_details["quantization"]
      test_image = test_image / input_scale + input_zero_point

    test_image = np.expand_dims(test_image, axis=0).astype(input_details["dtype"])
    interpreter.set_tensor(input_details["index"], test_image)
    interpreter.invoke()
    output = interpreter.get_tensor(output_details["index"])[0]
    # print(output)
    return output

def mc_eval_single_sample(test_image_index, tflite_file, no_itr, num_classes, conf_perc_factor, threshold):
    # Initialize the interpreter
    threshold = (threshold/output_scale) + output_zero_point
    interpreter = tf.lite.Interpreter(model_path=str(tflite_file), num_threads=multiprocessing.cpu_count())
    interpreter.allocate_tensors()

    input_details = interpreter.get_input_details()[0]
    output_details = interpreter.get_output_details()[0]

    test_image = x_test[test_image_index]
    test_label = y_test[test_image_index]

    conf_level_factor = np.sqrt(2) * erfinv(conf_perc_factor)
    predictions = np.zeros((no_itr, num_classes))

    for i in range(no_itr):
        predictions[i] = run_tflite_model_single_sample_raw(interpreter, input_details, output_details, test_image, test_label)

    avg_preds = predictions.mean(axis = 0)
    sd_preds = predictions.std(axis = 0)
    final_pred = np.zeros(num_classes)

    for i in range(num_classes):
        conf_int_low = avg_preds[i] - conf_level_factor*sd_preds[i]
        conf_int_up = avg_preds[i] + conf_level_factor*sd_preds[i]

        if conf_int_low > threshold:
            final_pred[i] = 1
        elif conf_int_up < threshold:
            final_pred[i] = 0
        else:
            final_pred[i] = -1

    return final_pred

def run_mc_eval_on_dataset(tflite_file, no_itr, num_classes, conf_perc_factor, threshold):
    threshold = (threshold/output_scale) + output_zero_point
    conf_level_factor = np.sqrt(2) * erfinv(conf_perc_factor)
    # Initialize the interpreter
    interpreter = tf.lite.Interpreter(model_path=str(tflite_file), num_threads=multiprocessing.cpu_count())
    interpreter.allocate_tensors()
    input_details = interpreter.get_input_details()[0]
    output_details = interpreter.get_output_details()[0]
    test_image_indices = range(x_test.shape[0])
    test_image_indices = range(100)
    final_predictions = np.zeros((len(test_image_indices), num_classes))
    for i, test_image_index in enumerate(test_image_indices):
        test_image = x_test[test_image_index]
        test_label = y_test[test_image_index]

        predictions = np.zeros((no_itr, num_classes))
        for k in range(no_itr):
            predictions[k] = run_tflite_model_single_sample_raw(interpreter, input_details, output_details, test_image, test_label)

        avg_preds = predictions.mean(axis = 0)
        sd_preds = predictions.std(axis = 0)
        final_pred = np.zeros(num_classes)

        for j in range(num_classes):
            conf_int_low = avg_preds[j] - conf_level_factor*sd_preds[j]
            conf_int_up = avg_preds[j] + conf_level_factor*sd_preds[j]

            if conf_int_low > threshold:
                final_pred[j] = 1
            elif conf_int_up < threshold:
                final_pred[j] = 0
            else:
                final_pred[j] = -1
        final_predictions[i] = final_pred
    return final_predictions

def evaluate_predictions(predictions, truths):
    confident_predictions = []
    selected_truths = []
    for i in range(len(truths)):
        current_prediction = np.copy(predictions[i])
        if np.any(np.isin(current_prediction, [-1])):
            if np.any(np.isin(current_prediction, [1])):
                current_prediction[current_prediction == -1] = 0
                confident_predictions.append(current_prediction)
                selected_truths.append(truths[i])
            elif(np.count_nonzero(current_prediction==-1) <= 1):
                current_prediction[current_prediction == -1] = 1
                confident_predictions.append(current_prediction)
                selected_truths.append(truths[i])

            else:
                print("Ignored",i)
        else:
            # print(current_prediction,i)
            confident_predictions.append(current_prediction)
            selected_truths.append(truths[i])

    uncertain_predictions = len(predictions) - len(confident_predictions)
    print('predictions were ignored: ', uncertain_predictions)

    return f1_score(selected_truths, confident_predictions, average='micro'), accuracy_score(selected_truths, confident_predictions)

tflite_models_dir = 'drive/MyDrive/DL_Project/CFAR100/'
model_file_name = 'cfar100_model_quantized_int8.tflite'

p = mc_eval_single_sample(67, tflite_models_dir+model_file_name, 10, num_classes, 0.9, 0.5)
p_whole = run_mc_eval_on_dataset(tflite_models_dir+model_file_name, 10, num_classes, 0.9, 0.5)

y_test[105]

interpreter = tf.lite.Interpreter(tflite_models_dir+model_file_name, num_threads=multiprocessing.cpu_count())
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()[0]
output_details = interpreter.get_output_details()[0]
test_image = x_test[77]
op = np.zeros((50, 100))
for i in range(50):
    op[i] = run_tflite_model_single_sample_raw(interpreter, input_details, output_details, test_image)

op[:, 10]

import matplotlib.pyplot as plt
data = op[:, 10]
# #create histogram
# plt.hist(data, color='lightgreen', ec='black', bins = 200)
import seaborn as sns

#create histogram with density curve overlaid
ax = sns.displot(data, kde=True, bins=10)
ax.set(xlabel="Network output value", ylabel='Occurence (count)')
plt.show()

"""# **Grid-Search CV on MC Dropouts**"""

num_iters = [20,30,50]
conf_factors = [0.7, 0.8, 0.9]
for num_iter in num_iters:
    for conf_factor in conf_factors:
        p_whole = run_mc_eval_on_dataset(tflite_models_dir+model_file_name, num_iter, num_classes, conf_factor, 0.5)
        print("For num_iter = " + str(num_iter) + ", conf_factor: " + str(conf_factor))
        print(evaluate_predictions(p_whole, y_test[:100]))

"""# **Inference on CIFAR-100C using the best-parameters**"""

def inference_on_data(x_test, y_test, tflite_file, no_itr, num_classes, conf_perc_factor, threshold):
    threshold = (threshold/output_scale) + output_zero_point
    conf_level_factor = np.sqrt(2) * erfinv(conf_perc_factor)
    # Initialize the interpreter
    interpreter = tf.lite.Interpreter(model_path=str(tflite_file), num_threads=multiprocessing.cpu_count())
    interpreter.allocate_tensors()
    input_details = interpreter.get_input_details()[0]
    output_details = interpreter.get_output_details()[0]
    test_image_indices = range(x_test.shape[0])
    final_predictions = np.zeros((len(test_image_indices), num_classes))
    for i, test_image_index in enumerate(test_image_indices):
        test_image = x_test[test_image_index]
        test_label = y_test[test_image_index]

        predictions = np.zeros((no_itr, num_classes))
        for k in range(no_itr):
            predictions[k] = run_tflite_model_single_sample_raw(interpreter, input_details, output_details, test_image, test_label)

        avg_preds = predictions.mean(axis = 0)
        sd_preds = predictions.std(axis = 0)
        final_pred = np.zeros(num_classes)

        for j in range(num_classes):
            conf_int_low = avg_preds[j] - conf_level_factor*sd_preds[j]
            conf_int_up = avg_preds[j] + conf_level_factor*sd_preds[j]

            if conf_int_low > threshold:
                final_pred[j] = 1
            elif conf_int_up < threshold:
                final_pred[j] = 0
            else:
                final_pred[j] = -1
        final_predictions[i] = final_pred
    return final_predictions

# Helper function to run inference on a TFLite model
def run_tflite_model_new(tflite_file, x_test, y_test, test_image_indices):

  # Initialize the interpreter
  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))
  interpreter.allocate_tensors()

  input_details = interpreter.get_input_details()[0]
  output_details = interpreter.get_output_details()[0]

  predictions = np.zeros((len(test_image_indices), 100))
  for i, test_image_index in enumerate(test_image_indices):
    test_image = x_test[test_image_index]
    test_label = y_test[test_image_index]

    # Check if the input type is quantized, then rescale input data to uint8
    if input_details['dtype'] == np.uint8:
      input_scale, input_zero_point = input_details["quantization"]
      test_image = test_image / input_scale + input_zero_point

    test_image = np.expand_dims(test_image, axis=0).astype(input_details["dtype"])
    interpreter.set_tensor(input_details["index"], test_image)
    interpreter.invoke()
    output = interpreter.get_tensor(output_details["index"])[0]
    max_index = np.argmax(output)
    # print(max_index)
    predictions[i][max_index] = 1

  return predictions

# Helper function to evaluate a TFLite model on all images
def evaluate_model_new(x_test, y_test, tflite_file, model_type):
  print(len(x_test))
  test_image_indices = range(x_test.shape[0])
  predictions = run_tflite_model_new(tflite_file, x_test, y_test, test_image_indices)
  accuracy = accuracy_score(predictions, y_test)*100
  f1_score_val = f1_score(predictions, y_test, average='micro')*100

  print(model_type + " accuracy is: " + str(accuracy))
  print(model_type + " f1-score is: " + str(f1_score_val))

# Specify the path to your .tar file
tar_file_path = 'drive/MyDrive/DL_Project/CFAR100/CIFAR-100-C.tar'

# Open the .tar file
with tarfile.open(tar_file_path, 'r') as tar:
    # Extract all files in the .tar file to the current directory
    tar.extractall()

dir_path = 'CIFAR-100-C/'
dir_files = os.listdir(dir_path)
# dir_files = dir_files[8:]
print(dir_files)
for file in dir_files:

    if(file == 'labels.npy' or file == 'README.txt'):
        continue

    elif(file == 'gaussian_noise.npy'):
        x_test_new = np.load(dir_path + file)
        x_test_new = x_test_new[40000:]
        x_test_new = x_test_new[:20]
        y_test_new = y_test[:20]
        print("Running inference for: ", file)
        # print("Inference on 20 images of severity 5 without MC Dropouts: ")
        evaluate_model_new(x_test_new, y_test_new, tflite_models_dir+model_file_name, "Quantized")
        # print("Inference on 20 images of s everity 1 using MC Dropouts: ")
        # p_whole = inference_on_data(x_test_new, y_test_new, tflite_models_dir+model_file_name, 30, num_classes, 0.7, 0.5)
        # print(evaluate_predictions(p_whole, y_test_new))
        print("Inference on 20 images of severity 5 using MC Dropouts: ")
        p_whole = inference_on_data(x_test_new, y_test_new, tflite_models_dir+model_file_name, 50, num_classes, 0.8, 0.5)
        print(evaluate_predictions(p_whole, y_test_new))
        print()

for i in range(20):
  print(p_whole[i])

y_test_new[19]

evaluate_predictions(p_whole, y_test[:100])

fine_labels = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']

fine_labels[67], fine_labels[85], fine_labels[27]

import matplotlib.pyplot as plt
index_pic = 92
print(list(y_test[index_pic]).index(1))
print(fine_labels[list(y_test[index_pic]).index(1)])
print(x_test[index_pic].shape)
plt.imshow(x_test[index_pic])

print(0.5/output_scale + output_zero_point)

# Specify the path to your .tar file
tar_file_path = 'drive/MyDrive/DL_Project/CFAR100/CIFAR-100-C.tar'

# Open the .tar file
with tarfile.open(tar_file_path, 'r') as tar:
    # Extract all files in the .tar file to the current directory
    tar.extractall()

img_set1 = np.load('CIFAR-100-C/gaussian_noise.npy')

img_set1 = img_set1[40000:]

print(len(np.load('CIFAR-100-C/brightness.npy')))

img_set1 = img_set1[:100]

img_set1 = img_set1.astype(np.float32) / 255.0



# Number of images
num_images = len(img_set1)

# Set up the subplot grid dynamically based on the number of images
num_cols = 10
num_rows = -(-num_images // num_cols)  # Equivalent to math.ceil(num_images / num_cols)

# Set the figure size
fig, axes = plt.subplots(num_rows, num_cols, figsize=(30, 20))

# Flatten the axes array to iterate over all subplots
axes = axes.flatten()

# Create subplots
for i in range(num_images):
    axes[i].imshow(img_set1[i], aspect='auto')  # Use cmap if the images are grayscale
    axes[i].set_title(f'Image {i + 1}')

# Hide empty subplots if there are more subplots than images
for j in range(num_images, num_rows * num_cols):
    fig.delaxes(axes[j])

# Adjust layout for better display
plt.tight_layout()

# Show the plot
plt.show()

p_whole = run_mc_eval_on_dataset(tflite_models_dir+model_file_name, 10, num_classes, 0.9, 0.5)

# Number of images
num_images = 100

# Set up the subplot grid dynamically based on the number of images
num_cols = 10
num_rows = -(-num_images // num_cols)  # Equivalent to math.ceil(num_images / num_cols)

# Set the figure size
fig, axes = plt.subplots(num_rows, num_cols, figsize=(30, 20))

# Flatten the axes array to iterate over all subplots
axes = axes.flatten()

# Create subplots
for i in range(num_images):
    axes[i].imshow(x_test[i], aspect='auto')  # Use cmap if the images are grayscale
    axes[i].set_title(f'Image {i + 1}')

# Hide empty subplots if there are more subplots than images
for j in range(num_images, num_rows * num_cols):
    fig.delaxes(axes[j])

# Adjust layout for better display
plt.tight_layout()

# Show the plot
plt.show()